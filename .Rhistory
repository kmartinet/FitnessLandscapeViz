# Combine linear and quadratic gradients into a data frame
selection_gradients <- data.frame(
Trait = names(linear_selection_gradients),
Linear_Gradient = linear_selection_gradients,
Linear_p_value = linear_p_values,
Generation = i,
zi_Linear_Gradient = zi_l_selection_gradients,
zi_Linear_p_value = zi_linear_p_values
)
# Add this generation's info to the mega df
mega_selection_gradients <- rbind(mega_selection_gradients, selection_gradients)
View(mega_selection_gradients)
View(mega_anova_results)
# Save ANOVA results for the current trait
names <- c("Intercept", t, "evolution", "Health:evolution")
mega_anova_df <- data.frame()
g <- 1
anova_df <- data.frame(
Trait = names,
Chisq = mega_anova_results[[g]][["Chisq"]],
Df = mega_anova_results[[g]][["Df"]],
p_value = mega_anova_results[[g]][["Pr(>Chisq)"]],
generation = g
)
View(anova_df)
csv_name <- paste0("mega_anova_df_AllBurrow_", t, ".csv")
setwd("C:/Users/KMart/Documents/Manuscripts/ProjectHasturPredictability/ANOVA_Files")
# Specify traits of interest
traits <-  c("Health", "SightRange", "Armor", "Damage", "WalkSpeed", "RunSpeed",
"Acceleration", "TurnRate", "Swim", "Jump", "ColliderSurfaceArea",
"Attraction0", "Attraction1", "Attraction2")
setwd("C:/Users/KMart/Documents/Manuscripts/ProjectHasturPredictability/ANOVA_Files")
# Create dataframe to hold all the good info
mega_selection_gradients <- data.frame()
for(t in traits){
# For each trait, do a GLMM across all evolutionary treatments and save ANOVA info
# Do this for select generations (every 10ish)
mega_anova_results <- list()
for(i in c(1, 10, 20, 30, 40, 48)){
# Grab data from the generation of interest
gen_dat <- dat[which(dat$Generation == i),]
# Filter data to the traits of interest
data <- gen_dat[t]
# Instead of relative fitness, what about number of babies?
fitness <- gen_dat$Offspring
# Grab replicate number
replicate <- gen_dat$replicate
evolution <- gen_dat$Evolution
# Standardize traits (mean of 0, sd of 1)
traits_standardized <- scale(data)
# Create df including both standardized traits and fitness
standardized_data <- as.data.frame(traits_standardized)
standardized_data$fitness <- fitness
standardized_data$replicate <- replicate
standardized_data$evolution <- evolution
trait <- colnames(standardized_data)[1] # Trait name is the name of the first column
formula <- as.formula(paste("fitness ~ ", trait, " + evolution", "+", trait, "*evolution +", "(1|replicate)"))
glmm_nb_model <- glmmTMB(formula, data = standardized_data, family = nbinom2, ziformula = ~ .)
glmm_nb_summary <- summary(glmm_nb_model)
coefficients <- glmm_nb_summary[["coefficients"]][["cond"]]
# Extract and exponentiate the coefficient for standardized_trait
beta <- coefficients[,1]
# Need to exponentiate, but don't want to lose the direction of selection (sign)
exp_beta <- beta
for(j in 1:length(exp_beta)){
if(exp_beta[[j]] < 0){
exp_beta[[j]] <- exp(beta[[j]]) * -1
} else{
exp_beta[[j]] <- exp(beta[[j]])
}
}
linear_selection_gradients <- exp_beta[-1]
linear_p_values <- coefficients[,4]
linear_p_values <- linear_p_values[-1] # exclude intercept
# If the zero inflation model has any significant results, it should probably be considered too, right?
zi_coeff <- glmm_nb_summary[["coefficients"]][["zi"]]
# Extract and exponentiate the coefficient for standardized_trait
zi_beta <- zi_coeff[,1]
# Need to exponentiate, but don't want to lose the direction of selection (sign)
zi_exp_beta <- zi_beta
for(k in 1:length(zi_exp_beta)){
if(zi_exp_beta[[k]] < 0){
zi_exp_beta[[k]] <- exp(beta[[k]]) * -1
} else{
zi_exp_beta[[k]] <- exp(beta[[k]])
}
}
# Gather values
zi_l_selection_gradients <- zi_exp_beta[-1] #exclude intercept
# Gather p-values
zi_linear_p_values <- zi_coeff[,4]
zi_linear_p_values <- zi_linear_p_values[-1] # exclude intercept
# Get ANOVA results
mega_anova_results[[i]] <- Anova(glmm_nb_model, type="3")
# Combine linear and quadratic gradients into a data frame
selection_gradients <- data.frame(
Trait = names(linear_selection_gradients),
Linear_Gradient = linear_selection_gradients,
Linear_p_value = linear_p_values,
Generation = i,
zi_Linear_Gradient = zi_l_selection_gradients,
zi_Linear_p_value = zi_linear_p_values
)
# Add this generation's info to the mega df
mega_selection_gradients <- rbind(mega_selection_gradients, selection_gradients)
}
# Save ANOVA results for the current trait
names <- c("Intercept", t, "evolution", "Health:evolution")
mega_anova_df <- data.frame()
for(g in c(1, 10, 20, 30, 40, 48)){
anova_df <- data.frame(
Trait = names,
Chisq = mega_anova_results[[g]][["Chisq"]],
Df = mega_anova_results[[g]][["Df"]],
p_value = mega_anova_results[[g]][["Pr(>Chisq)"]],
generation = g
)
mega_anova_df <- rbind(mega_anova_df, anova_df)
csv_name <- paste0("mega_anova_df_AllBurrow_", t, ".csv")
write.csv(mega_anova_df, csv_name)
}
# Once the current trait's dataframe is written to a file, go to the next trait
}
warings()
warnings()
View(mega_selection_gradients)
write.csv(mega_selection_gradients, "mega_selection_gradients_ANOVA_run.csv")
View(gen_dat)
setwd("C:/Users/KMart/Documents")
View(dat)
i <- 20
t <- "WalkSpeed"
# Grab data from the generation of interest
gen_dat <- dat[which(dat$Generation == i),]
# Filter data to the traits of interest
data <- gen_dat[t]
# Instead of relative fitness, what about number of babies?
fitness <- gen_dat$Offspring
# Grab replicate number
replicate <- gen_dat$replicate
evolution <- gen_dat$Evolution
# Standardize traits (mean of 0, sd of 1)
traits_standardized <- scale(data)
View(data)
View(gen_dat)
# Create df including both standardized traits and fitness
standardized_data <- as.data.frame(traits_standardized)
standardized_data$fitness <- fitness
standardized_data$replicate <- replicate
standardized_data$evolution <- evolution
trait <- colnames(standardized_data)[1] # Trait name is the name of the first column
formula <- as.formula(paste("fitness ~ ", trait, " + evolution", "+", trait, "*evolution +", "(1|replicate)"))
glmm_nb_model <- glmmTMB(formula, data = standardized_data, family = nbinom2, ziformula = ~ .)
fixef(glmm_nb_model)$cond
glmm_nb_summary <- summary(glmm_nb_model)
# Extract initial estimates for the fixed effects
initial_fixed_effects <- fixef(glmm_nb_model)$cond
# Specify custom starting values for optimization
start_values <- list(beta = initial_fixed_effects)
# Fit the GLMM with Zero-Inflated Negative Binomial distribution using custom starting values
glmm_nb_model2 <- glmmTMB(formula,
data = standardized_data, family = nbinom2(), ziformula = ~ .,
start = start_values)
View(glmm_nb_summary)
glmm_nb_summary
beta <- coefficients[,1]
beta
coefficients <- glmm_nb_summary[["coefficients"]][["cond"]]
# Specify custom starting values for optimization
start_values <- list(beta = coefficients)
# Fit the GLMM with Zero-Inflated Negative Binomial distribution using custom starting values
glmm_nb_model2 <- glmmTMB(formula,
data = standardized_data, family = nbinom2(), ziformula = ~ .,
start = start_values)
View(coefficients)
coefficients[,1]
# Specify custom starting values for optimization
start_values <- list(beta = coefficients[,1])
# Fit the GLMM with Zero-Inflated Negative Binomial distribution using custom starting values
glmm_nb_model2 <- glmmTMB(formula,
data = standardized_data, family = nbinom2(), ziformula = ~ .,
start = start_values)
typeof(coefficients[,1])
?runif
# Specify custom starting values for optimization
start_values <- list(beta = runif(8, 0, 2))
View(start_values)
start_values[["beta"]]
# Specify custom starting values for optimization
raw_values <- runif(8, 0, 2)
names(raw_values) <- names(coefficients[,1])
raw_values
coefficients[,1]
start_values <- list(beta = raw_values)
# Fit the GLMM with Zero-Inflated Negative Binomial distribution using custom starting values
glmm_nb_model2 <- glmmTMB(formula,
data = standardized_data, family = nbinom2(), ziformula = ~ .,
start = start_values)
# Specify custom starting values for optimization
raw_values <- runif(8, 0, 2)
names(raw_values) <- names(coefficients[,1])
start_values <- list(beta = raw_values)
# Fit the GLMM with Zero-Inflated Negative Binomial distribution using custom starting values
glmm_nb_model2 <- glmmTMB(formula,
data = standardized_data, family = nbinom2(), ziformula = ~ .,
start = start_values)
glmm_nb_summary <- summary(glmm_nb_model2)
coefficients <- glmm_nb_summary[["coefficients"]][["cond"]]
glmm_nb_model <- glmmTMB(formula, data = standardized_data, family = nbinom2, ziformula = ~ .)
glmm_nb_summary <- summary(glmm_nb_model)
glmm_nb_summary
View(glmm_nb_summary)
glmm_nb_summary[["Pr(>|z|"]]
summary(glmm_nb_model2)[["Pr(>|z|"]]
summary(glmm_nb_model2)
View(glmm_nb_model2)
summary2 <- summary(glmm_nb_model2)
View(summary2)
summary2[["logLik"]]
glmm_nb_summary[["logLik"]]
if(glmm_nb_summary[["logLik"]]==TRUE){print("yay")}
if(glmm_nb_summary[["logLik"]]==NA){print("yay")}
if(is.na(glmm_nb_summary[["logLik"]])){print("yay")}
glmm_nb_model <- glmmTMB(formula, data = standardized_data, family = nbinom2, ziformula = ~ .)
glmm_nb_summary <- summary(glmm_nb_model)
coefficients <- glmm_nb_summary[["coefficients"]][["cond"]]
# Is a while loop okay for this??
while(is.na(glmm_nb_summary[["logLik"]])){
print("Entered while loop")
# Extract initial estimates for the fixed effects
#initial_fixed_effects <- fixef(glmm_nb_model)$cond
# Specify custom starting values for optimization
raw_values <- runif(8, 0, 2)
names(raw_values) <- names(coefficients[,1])
start_values <- list(beta = raw_values)
# Fit the GLMM with Zero-Inflated Negative Binomial distribution using custom starting values
glmm_nb_model2 <- glmmTMB(formula,
data = standardized_data, family = nbinom2(), ziformula = ~ .,
start = start_values)
glmm_nb_summary <- summary(glmm_nb_model2)
# If not NA, stop the while loop
if(!is.na(glmm_nb_summary[["logLik"]])){
print("While loop stopping")
coefficients <- glmm_nb_summary[["coefficients"]][["cond"]]
break
}
}
View(glmm_nb_summary)
glmm_nb_summary
library(geiger)
install.packages("geiger")
library(geiger)
?geiger
library(cars)
library(car)
?Anova
# Load packages
library(mgcv)
library(rgl)
setwd("C:/Users/KMart/Documents/GitHub/FitnessLandscapeViz")
# Load data
data <- read.csv("data/OnlyFit_K_Burrow_Gen0-48.csv")
# Load data
data <- read.csv("./data/OnlyFit_K_Burrow_Gen0-48.csv")
View(data)
# Filter data
KSB6_28 <- which(data$replicate == 6 && data$Generation == 28)
# Filter data
KSB6_28 <- which(data$replicate == 6)
# Filter data
KSB6 <- which(data$replicate == 6)
# Filter data
KSB6 <- data[which(data$replicate == 6),]
View(KSB6)
# Get data from generation 28
KSB6_28 <- KSB6[which(KSB6$Generation == 28),]
View(KSB6_28)
# Designate traits of interest
traits <-  c("Health", "SightRange", "Armor", "Damage", "WalkSpeed", "RunSpeed",
"Acceleration", "TurnRate", "Swim", "Jump", "ColliderSurfaceArea",
"Attraction0", "Attraction1", "Attraction2")
# Create new dataframe with just traits of interest
trait_dat <- KSB6_28[traits]
View(trait_dat)
# Standardize traits (mean of 0, sd of 1)
traits_standardized <- scale(trait_dat)
# Perform PCA to reduce dimensionality
pca_model <- prcomp(traits_standardized, center = TRUE, scale. = TRUE)
pca_scores <- pca_model$x
# Combine PCA scores with fitness
fitness_data <- as.data.frame(cbind(pca_scores, fitness=fitness))
# Save fitness values
# I choose relfit here, which is fitness based on the number of offspring each Protean produced
fitness <- KSB6_28$relfit
# Load packages
library(mgcv) # For fitting GAMs
library(rgl)  # For creating 3D plots
# Load data
data <- read.csv("./data/OnlyFit_K_Burrow_Gen0-48.csv")
# Filter data
# I am interested in visualizing the fitness landscape for one generation in one replicate
# Get data from replicate 6
KSB6 <- data[which(data$replicate == 6),]
# Get data from generation 28 (I know this one looks cool)
KSB6_28 <- KSB6[which(KSB6$Generation == 28),]
# Designate traits of interest
traits <-  c("Health", "SightRange", "Armor", "Damage", "WalkSpeed", "RunSpeed",
"Acceleration", "TurnRate", "Swim", "Jump", "ColliderSurfaceArea",
"Attraction0", "Attraction1", "Attraction2")
# Create new dataframe with just traits of interest
trait_dat <- KSB6_28[traits]
# Save fitness values
# I choose relfit here, which is fitness based on the number of offspring each Protean produced
fitness <- KSB6_28$relfit
# Standardize traits (mean of 0, sd of 1)
traits_standardized <- scale(trait_dat)
# Perform PCA to reduce dimensionality
pca_model <- prcomp(traits_standardized, center = TRUE, scale. = TRUE)
pca_scores <- pca_model$x
# Combine PCA scores with fitness
fitness_data <- as.data.frame(cbind(pca_scores, fitness=fitness))
View(fitness_data)
# Fit a GAM model using cubic splines
# Inspired by the methods in Stroud, J.T., Moore, M.P., Langerhans, R.B., & Losos, J.B. 2023. Fluctuating selection maintains distinct species phenotypes in an ecological community in the wild. PNAS 120(42):e2222071120
gam_model <- gam(fitness ~ s(PC1, bs = "cs") + s(PC2, bs = "cs"), data = fitness_data)
summary(gam_model)
# Prepare data for surface heatmap
grid <- expand.grid(PC1 = seq(min(fitness_data$PC1), max(fitness_data$PC1), length=100),
PC2 = seq(min(fitness_data$PC2), max(fitness_data$PC2), length=100))
# Predict fitness over the grid to create a smooth surface for plotting
grid$fitness <- predict(gam_model, newdata = grid)
# Convert grid to matrices for plotting
PC1_matrix <- matrix(grid$PC1, nrow = 100, ncol = 100)
PC2_matrix <- matrix(grid$PC2, nrow = 100, ncol = 100)
fitness_matrix <- matrix(grid$fitness, nrow = 100, ncol = 100)
# Create 3D scatter plot of the original data
plot3d(x = fitness_data$PC1, y = fitness_data$PC2, z = fitness_data$fitness,
type = "s", size = 1, col = "blue", xlab = "PC1", ylab = "PC2", zlab = "Fitness")
# Add the surface plot of the predicted fitness values
surface3d(PC1_matrix, PC2_matrix, fitness_matrix, color = "red", alpha = 0.5)
# Create and save 3D plot of fitness landscape
filename <- "./Data/KSB6_28.rds"
open3d()
# Create 3D scatter plot of the original data
plot3d(x = fitness_data$PC1, y = fitness_data$PC2, z = fitness_data$fitness,
type = "s", size = 1, col = "blue", xlab = "PC1", ylab = "PC2", zlab = "Fitness", main = "KSB9 Gen 30")
# Add the surface plot of the predicted fitness values
surface3d(PC1_matrix, PC2_matrix, fitness_matrix, color = "red", alpha = 0.5)
rgl.snapshot(filename)
scene <- scene3d()
saveRDS(scene, filename)
close3d()
# Create and save 3D plot of fitness landscape
filename <- "./Data/KSB6_28.rds"
plot_title <- "KSB6 Gen 28"
open3d()
# Create 3D scatter plot of the original data
plot3d(x = fitness_data$PC1, y = fitness_data$PC2, z = fitness_data$fitness,
type = "s", size = 1, col = "blue", xlab = "PC1", ylab = "PC2", zlab = "Fitness", main = plot_title)
# Add the surface plot of the predicted fitness values
surface3d(PC1_matrix, PC2_matrix, fitness_matrix, color = "red", alpha = 0.5)
rgl.snapshot(filename)
scene <- scene3d()
saveRDS(scene, filename)
close3d()
# Load packages
library(mgcv)
library(rgl)
# Load packages
library(mgcv)
library(rgl)
# Load data
data <- read.csv("./data/OnlyFit_K_Burrow_Gen0-48.csv")
# Traits of interest
traits <-  c("Health", "SightRange", "Armor", "Damage", "WalkSpeed", "RunSpeed",
"Acceleration", "TurnRate", "Swim", "Jump", "ColliderSurfaceArea",
"Attraction0", "Attraction1", "Attraction2")
# Choosing replicate 1
rep <- 1
# Filter data
dat_rep <- data[which(data$replicate == rep),]
g <- 25
dat_gen <- dat_rep[which(dat_rep$Generation == g),]
View(dat_gen)
dat_traits <- dat_gen[traits]
fitness <- dat_gen$relfit
# Standardize traits (mean of 0, sd of 1 for each column)
traits_standardized <- scale(dat_traits)
dat_rep <- data[which(data$replicate == rep),]
dat_gen <- dat_rep[which(dat_rep$Generation == g),]
dat_traits <- dat_gen[traits]
fitness <- dat_gen$relfit
# Standardize traits (mean of 0, sd of 1 for each column)
traits_standardized <- scale(dat_traits)
# Perform PCA to reduce dimensionality
pca_model <- prcomp(traits_standardized, center = TRUE, scale. = TRUE)
pca_scores <- pca_model$x
# Combine PCA scores with fitness
fitness_data <- as.data.frame(cbind(pca_scores, fitness=fitness))
# Fit a GAM using cubic splines
gam_model <- gam(fitness ~ s(PC1, bs = "cs") + s(PC2, bs = "cs"), data = fitness_data)
# Prepare data for surface heatmap
grid <- expand.grid(PC1 = seq(min(fitness_data$PC1), max(fitness_data$PC1), length=100),
PC2 = seq(min(fitness_data$PC2), max(fitness_data$PC2), length=100))
grid$fitness <- predict(gam_model, newdata = grid)
# Convert grid to matrices for plotting
PC1_matrix <- matrix(grid$PC1, nrow = 100, ncol = 100)
PC2_matrix <- matrix(grid$PC2, nrow = 100, ncol = 100)
fitness_matrix <- matrix(grid$fitness, nrow = 100, ncol = 100)
# Create and save 3D plot of fitness landscape
filename <- paste0("./Data/", prefix, r, "_", g, ".rds")
# Designate prefix for .rds file name
prefix <- "KSB"
# Create and save 3D plot of fitness landscape
filename <- paste0("./Data/", prefix, r, "_", g, ".rds")
# Create and save 3D plot of fitness landscape
filename <- paste0("./Data/", prefix, rep, "_", g, ".rds")
filename
plot_title <- paste0(prefix, rep, " Gen ", g)
plot_title
# Filter data
dat_rep <- data[which(data$replicate == rep),]
dat_gen <- dat_rep[which(dat_rep$Generation == g),]
dat_traits <- dat_gen[traits]
fitness <- dat_gen$relfit
# Standardize traits (mean of 0, sd of 1 for each column)
traits_standardized <- scale(dat_traits)
# Perform PCA to reduce dimensionality
pca_model <- prcomp(traits_standardized, center = TRUE, scale. = TRUE)
pca_scores <- pca_model$x
# Combine PCA scores with fitness
fitness_data <- as.data.frame(cbind(pca_scores, fitness=fitness))
# Fit a GAM using cubic splines
gam_model <- gam(fitness ~ s(PC1, bs = "cs") + s(PC2, bs = "cs"), data = fitness_data)
# Prepare data for surface heatmap
grid <- expand.grid(PC1 = seq(min(fitness_data$PC1), max(fitness_data$PC1), length=100),
PC2 = seq(min(fitness_data$PC2), max(fitness_data$PC2), length=100))
grid$fitness <- predict(gam_model, newdata = grid)
# Convert grid to matrices for plotting
PC1_matrix <- matrix(grid$PC1, nrow = 100, ncol = 100)
PC2_matrix <- matrix(grid$PC2, nrow = 100, ncol = 100)
fitness_matrix <- matrix(grid$fitness, nrow = 100, ncol = 100)
# Create and save 3D plot of fitness landscape
filename <- paste0("./Data/", prefix, rep, "_", g, ".rds")
plot_title <- paste0(prefix, rep, " Gen ", g)
open3d()
# Create 3D scatter plot of the original data
plot3d(x = fitness_data$PC1, y = fitness_data$PC2, z = fitness_data$fitness,
type = "s", size = 1, col = "blue", xlab = "PC1", ylab = "PC2", zlab = "Fitness", main = plot_title)
# Add the surface plot of the predicted fitness values
surface3d(PC1_matrix, PC2_matrix, fitness_matrix, color = "red", alpha = 0.5)
rgl.snapshot(filename)
scene <- scene3d()
saveRDS(scene, filename)
close3d()
# Load packages
library(mgcv)
library(rgl)
# Load data
data <- read.csv("./data/OnlyFit_K_Burrow_Gen0-48.csv")
# Traits of interest
traits <-  c("Health", "SightRange", "Armor", "Damage", "WalkSpeed", "RunSpeed",
"Acceleration", "TurnRate", "Swim", "Jump", "ColliderSurfaceArea",
"Attraction0", "Attraction1", "Attraction2")
# Choosing replicate 1
rep <- 1
# Designate prefix for .rds file name
prefix <- "KSB"
# Let's say I'd like to create .rds files for generations 25-30
for(g in c(25:30)){
# Filter data
dat_rep <- data[which(data$replicate == rep),]
dat_gen <- dat_rep[which(dat_rep$Generation == g),]
dat_traits <- dat_gen[traits]
fitness <- dat_gen$relfit
# Standardize traits (mean of 0, sd of 1 for each column)
traits_standardized <- scale(dat_traits)
# Perform PCA to reduce dimensionality
pca_model <- prcomp(traits_standardized, center = TRUE, scale. = TRUE)
pca_scores <- pca_model$x
# Combine PCA scores with fitness
fitness_data <- as.data.frame(cbind(pca_scores, fitness=fitness))
# Fit a GAM using cubic splines
gam_model <- gam(fitness ~ s(PC1, bs = "cs") + s(PC2, bs = "cs"), data = fitness_data)
# Prepare data for surface heatmap
grid <- expand.grid(PC1 = seq(min(fitness_data$PC1), max(fitness_data$PC1), length=100),
PC2 = seq(min(fitness_data$PC2), max(fitness_data$PC2), length=100))
grid$fitness <- predict(gam_model, newdata = grid)
# Convert grid to matrices for plotting
PC1_matrix <- matrix(grid$PC1, nrow = 100, ncol = 100)
PC2_matrix <- matrix(grid$PC2, nrow = 100, ncol = 100)
fitness_matrix <- matrix(grid$fitness, nrow = 100, ncol = 100)
# Create and save 3D plot of fitness landscape
filename <- paste0("./Data/", prefix, rep, "_", g, ".rds")
plot_title <- paste0(prefix, rep, " Gen ", g)
open3d()
# Create 3D scatter plot of the original data
plot3d(x = fitness_data$PC1, y = fitness_data$PC2, z = fitness_data$fitness,
type = "s", size = 1, col = "blue", xlab = "PC1", ylab = "PC2", zlab = "Fitness", main = plot_title)
# Add the surface plot of the predicted fitness values
surface3d(PC1_matrix, PC2_matrix, fitness_matrix, color = "red", alpha = 0.5)
rgl.snapshot(filename)
scene <- scene3d()
saveRDS(scene, filename)
close3d()
}
filenames <- list.files(pattern = "./Data/KSB1*.rds")
# Get filenames ASSUMES DATA IS IN SUB-DIRECTORY
filenames <- list.files(pattern = "KSB1*.rds", recursive = TRUE)
# Get filenames ASSUMES DATA IS IN SUB-DIRECTORY
filenames <- list.files(pattern = "KSB1", recursive = TRUE)
filenames
